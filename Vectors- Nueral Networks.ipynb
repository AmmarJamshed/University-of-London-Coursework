{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "established-dining",
   "metadata": {},
   "source": [
    "# Vector features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "economic-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [304,-2, 0, 57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dietary-creator",
   "metadata": {},
   "source": [
    "# Vector features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "oriental-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [304,-2, 0, 57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "silver-wrong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [304, -2, 0, 57] \tlength: 4 \tx[2] = 0\n"
     ]
    }
   ],
   "source": [
    "# Print vector length and the third element\n",
    "print('x:', x, '\\tlength:', len(x), '\\tx[2] =', x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daily-discharge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 93 /trank: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array(93)\n",
    "print('x:', x, '/trank:', x.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prerequisite-pricing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [304  -2   0  57] /trank: 1\n"
     ]
    }
   ],
   "source": [
    "x = np.array([304,-2, 0, 57])\n",
    "print('x:', x, '/trank:', x.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "induced-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor with a single axis created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "honest-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frames pulled from tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "comprehensive-dealing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([3,7,5,1])\n",
    "print(x[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alternate-senior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 5]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([3,7,5,1])\n",
    "print(x[-3:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "consistent-seventh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  2]\n",
      "  [ 3  4]]\n",
      "\n",
      " [[ 5  6]\n",
      "  [ 7  8]]\n",
      "\n",
      " [[ 9 10]\n",
      "  [11 12]]] \t (3, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# stack for three (2,2) tensors\n",
    "a = np.array([[1,2], [3,4]])\n",
    "b = np.array([[5,6], [7,8]])\n",
    "c = np.array([[9,10], [11,12]])\n",
    "x = np.array([a,b,c])\n",
    "print(x, '\\t', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "built-snowboard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 2]\n",
      "  [3 4]]] \t (1, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# slice\n",
    "slice = x[0:1, :, :]\n",
    "print(slice, '\\t', slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "alike-reggae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 2]\n",
      "  [3 4]]] \t (1, 2, 2)\n",
      "\n",
      "[[[1 2]\n",
      "  [3 4]]] \t (1, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "slice =  x[:1, :, :]\n",
    "print(slice, '\\t', slice.shape)\n",
    "print()\n",
    "slice = x[:1]\n",
    "print(slice, '\\t', slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "korean-berkeley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b,c] = \n",
      " [[[ 5  6]\n",
      "  [ 7  8]]\n",
      "\n",
      " [[ 9 10]\n",
      "  [11 12]]]\n",
      "\n",
      "x[1:3] = \n",
      " [[[ 5  6]\n",
      "  [ 7  8]]\n",
      "\n",
      " [[ 9 10]\n",
      "  [11 12]]] \t (2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# [b,c]\n",
    "print('[b,c] = \\n', np.array([b,c]))\n",
    "slice = x[1:3]\n",
    "print('\\nx[1:3] = \\n', slice, '\\t', slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "certain-theme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 5s 0us/step\n",
      "(10, 28, 28)\n"
     ]
    }
   ],
   "source": [
    " # Slicing MNIST sensors \n",
    "from tensorflow.keras.datasets import mnist \n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# select images 10 through to image 9 \n",
    "slice = train_images[10:20]\n",
    "print(slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-holiday",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

   "id": "proud-climate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [304, -2, 0, 57] \tlength: 4 \tx[2] = 0\n"
     ]
    }
   ],
   "source": [
    "# Print vector length and the third element\n",
    "print('x:', x, '\\tlength:', len(x), '\\tx[2] =', x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unexpected-china",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 93 /trank: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array(93)\n",
    "print('x:', x, '/trank:', x.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "private-feedback",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [304  -2   0  57] /trank: 1\n"
     ]
    }
   ],
   "source": [
    "x = np.array([304,-2, 0, 57])\n",
    "print('x:', x, '/trank:', x.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "narrative-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor with a single axis created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-thing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
