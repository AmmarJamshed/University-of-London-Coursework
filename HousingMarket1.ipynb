{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows:  20434\n",
      "Number of Columns:  11\n",
      "LA:  2270\n",
      "LB:  2628\n",
      "LC:  6496\n",
      "LD:  9034\n",
      "T:  20428\n",
      "Train Features Task 1:  (2043, 8)\n",
      "Train Labels Task 1:  (2043,)\n",
      "Test Features Task 1:  (227, 8)\n",
      "Test Labels Task 1:  (227,)\n",
      "Train Features Task 2:  (2365, 8)\n",
      "Train Labels Task 2:  (2365,)\n",
      "Test Features Task 2:  (263, 8)\n",
      "Test Labels Task 2:  (263,)\n",
      "Train Features Task 3:  (5846, 8)\n",
      "Train Labels Task 3:  (5846,)\n",
      "Test Features Task 3:  (650, 8)\n",
      "Test Labels Task 3:  (650,)\n",
      "Train Features Task 4:  (8130, 8)\n",
      "Train Labels Task 4:  (8130,)\n",
      "Test Features Task 4:  (904, 8)\n",
      "Test Labels Task 4:  (904,)\n",
      "Task 1 Root Mean Square Error:  50184.1\n",
      "Task 1 Average Relative Error:  0.18\n",
      "Task 2 Root Mean Square Error:  56174.5\n",
      "Task 2 Average Relative Error:  0.18\n",
      "Task 3 Root Mean Square Error:  34625.73\n",
      "Task 3 Average Relative Error:  0.2\n",
      "Task 4 Root Mean Square Error:  50484.5\n",
      "Task 4 Average Relative Error:  0.15\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "\n",
    "# Single Task Learning\n",
    "# Use 4 locations (ocean proximity)\n",
    "# Location 5 is not used due to small number of data points\n",
    "\n",
    "# Update path according to file system\n",
    "PathToFile = str('')\n",
    "\n",
    "# Train and Test sizes\n",
    "TrainSize = float(0.9)\n",
    "TestSize = float(1.0 - TrainSize)\n",
    "\n",
    "# Label size\n",
    "LA = int(0.0)\n",
    "LB = int(0.0)\n",
    "LC = int(0.0)\n",
    "LD = int(0.0)\n",
    "T = int(0.0)\n",
    "\n",
    "# Removing rows with empty cells\n",
    "# Lines necessary only for the first run\n",
    "# MyDataP = pd.read_csv(PathToFile+'HousingMarket1.csv')\n",
    "# MyDataNewP = MyDataP.dropna(axis=0)\n",
    "# MyDataNewP.to_csv(PathToFile+'HousingMarket2.csv', sep=',', encoding='utf-8')\n",
    "\n",
    "# Acquire the datasets from the file system\n",
    "MyData = np.genfromtxt(PathToFile+'HousingMarket2.csv', delimiter=',', dtype='unicode')\n",
    "\n",
    "# Print dimensions of dataset\n",
    "print('Number of Rows: ', MyData.shape[0])\n",
    "print('Number of Columns: ', MyData.shape[1])\n",
    "\n",
    "# Extract dimensions of sub-datasets based on location (ocean proximity)\n",
    "for i in range(0, MyData.shape[0]):\n",
    "    if str(MyData[i][10]) == 'NEAR BAY':\n",
    "        LA = LA + 1\n",
    "    if str(MyData[i][10]) == 'NEAR OCEAN':\n",
    "        LB = LB + 1\n",
    "    if str(MyData[i][10]) == 'INLAND':\n",
    "        LC = LC + 1\n",
    "    if str(MyData[i][10]) == '<1H OCEAN':\n",
    "        LD = LD + 1\n",
    "\n",
    "# Total number of rows\n",
    "T = int(LA + LB + LC + LD)\n",
    "\n",
    "print('LA: ', LA)\n",
    "print('LB: ', LB)\n",
    "print('LC: ', LC)\n",
    "print('LD: ', LD)\n",
    "print('T: ', T)\n",
    "\n",
    "# Re-arranged dataset\n",
    "MyDataNew = np.empty(shape=(T, 9), dtype=float)\n",
    "# Features and labels for non stratified model\n",
    "Features = np.empty(shape=(MyData.shape[0]-1, 8), dtype=float)\n",
    "Labels = np.empty(shape=MyData.shape[0]-1, dtype=float)\n",
    "\n",
    "# Allocate memory for Features for Groups 1 to 4\n",
    "# Group 5 is not used due to small size\n",
    "FeaturesGroup1 = np.empty(shape=(LA, 8), dtype=float)\n",
    "FeaturesGroup2 = np.empty(shape=(LB, 8), dtype=float)\n",
    "FeaturesGroup3 = np.empty(shape=(LC, 8), dtype=float)\n",
    "FeaturesGroup4 = np.empty(shape=(LD, 8), dtype=float)\n",
    "\n",
    "# Allocate memory for Labels for Groups 1 to 4\n",
    "LabelsGroup1 = np.empty(shape=LA, dtype=float)\n",
    "LabelsGroup2 = np.empty(shape=LB, dtype=float)\n",
    "LabelsGroup3 = np.empty(shape=LC, dtype=float)\n",
    "LabelsGroup4 = np.empty(shape=LD, dtype=float)\n",
    "\n",
    "# Re-arrange dataset based on location (ocean proximity)\n",
    "k = int(0)\n",
    "for i in range(0, MyData.shape[0]):\n",
    "    if str(MyData[i][10]) == 'NEAR BAY':\n",
    "        for j in range(0, 9):\n",
    "            try:\n",
    "                MyDataNew[k][j] = float(MyData[i][j+1])\n",
    "            except:\n",
    "                print('Error')\n",
    "        k = k + 1\n",
    "k = int(0)\n",
    "for i in range(0, MyData.shape[0]):\n",
    "    if str(MyData[i][10]) == 'NEAR OCEAN':\n",
    "        for j in range(0, 9):\n",
    "            try:\n",
    "                MyDataNew[LA+k][j] = float(MyData[i][j+1])\n",
    "            except:\n",
    "                print('Error')\n",
    "        k = k + 1\n",
    "k = int(0)\n",
    "for i in range(0, MyData.shape[0]):\n",
    "    if str(MyData[i][10]) == 'INLAND':\n",
    "        for j in range(0, 9):\n",
    "            try:\n",
    "                MyDataNew[LA+LB+k][j] = float(MyData[i][j+1])\n",
    "            except:\n",
    "                print('Error')\n",
    "        k = k + 1\n",
    "k = int(0)\n",
    "for i in range(0, MyData.shape[0]):\n",
    "    if str(MyData[i][10]) == '<1H OCEAN':\n",
    "        for j in range(0, 9):\n",
    "            try:\n",
    "                MyDataNew[LA+LB+LC+k][j] = float(MyData[i][j+1])\n",
    "            except:\n",
    "                print('Error')\n",
    "        k = k + 1\n",
    "\n",
    "# Extract Groups from dataset\n",
    "for i in range(0, LA):\n",
    "    for j in range(0, 8):\n",
    "        FeaturesGroup1[i][j] = MyDataNew[i][j]\n",
    "    LabelsGroup1[i] = MyDataNew[i][8]\n",
    "for i in range(0, LB):\n",
    "    for j in range(0, 8):\n",
    "        FeaturesGroup2[i][j] = MyDataNew[LA+i][j]\n",
    "    LabelsGroup2[i] = MyDataNew[LA+i][8]\n",
    "for i in range(0, LC):\n",
    "    for j in range(0, 8):\n",
    "        FeaturesGroup3[i][j] = MyDataNew[LA+LB+i][j]\n",
    "    LabelsGroup3[i] = MyDataNew[LA+LB+i][8]\n",
    "for i in range(0, LD):\n",
    "    for j in range(0, 8):\n",
    "        FeaturesGroup4[i][j] = MyDataNew[LA+LB+LC+i][j]\n",
    "    LabelsGroup4[i] = MyDataNew[LA+LB+LC+i][8]\n",
    "\n",
    "# Split dataset\n",
    "TrainFeaturesG1, TestFeaturesG1, TrainLabelsG1, TestLabelsG1 = train_test_split(FeaturesGroup1, LabelsGroup1, test_size=TestSize, random_state=10)\n",
    "TrainFeaturesG2, TestFeaturesG2, TrainLabelsG2, TestLabelsG2 = train_test_split(FeaturesGroup2, LabelsGroup2, test_size=TestSize, random_state=20)\n",
    "TrainFeaturesG3, TestFeaturesG3, TrainLabelsG3, TestLabelsG3 = train_test_split(FeaturesGroup3, LabelsGroup3, test_size=TestSize, random_state=30)\n",
    "TrainFeaturesG4, TestFeaturesG4, TrainLabelsG4, TestLabelsG4 = train_test_split(FeaturesGroup4, LabelsGroup4, test_size=TestSize, random_state=40)\n",
    "\n",
    "# Confirm dimensionality\n",
    "print('Train Features Task 1: ', TrainFeaturesG1.shape)\n",
    "print('Train Labels Task 1: ', TrainLabelsG1.shape)\n",
    "print('Test Features Task 1: ', TestFeaturesG1.shape)\n",
    "print('Test Labels Task 1: ', TestLabelsG1.shape)\n",
    "print('Train Features Task 2: ', TrainFeaturesG2.shape)\n",
    "print('Train Labels Task 2: ', TrainLabelsG2.shape)\n",
    "print('Test Features Task 2: ', TestFeaturesG2.shape)\n",
    "print('Test Labels Task 2: ', TestLabelsG2.shape)\n",
    "print('Train Features Task 3: ', TrainFeaturesG3.shape)\n",
    "print('Train Labels Task 3: ', TrainLabelsG3.shape)\n",
    "print('Test Features Task 3: ', TestFeaturesG3.shape)\n",
    "print('Test Labels Task 3: ', TestLabelsG3.shape)\n",
    "print('Train Features Task 4: ', TrainFeaturesG4.shape)\n",
    "print('Train Labels Task 4: ', TrainLabelsG4.shape)\n",
    "print('Test Features Task 4: ', TestFeaturesG4.shape)\n",
    "print('Test Labels Task 4: ', TestLabelsG4.shape)\n",
    "\n",
    "# Initialise the Random Forest Regression objects\n",
    "rf1 = RandomForestRegressor(n_estimators=50, random_state=10)\n",
    "rf2 = RandomForestRegressor(n_estimators=50, random_state=20)\n",
    "rf3 = RandomForestRegressor(n_estimators=50, random_state=30)\n",
    "rf4 = RandomForestRegressor(n_estimators=50, random_state=40)\n",
    "\n",
    "# Train the model\n",
    "rf1.fit(TrainFeaturesG1, TrainLabelsG1)\n",
    "rf2.fit(TrainFeaturesG2, TrainLabelsG2)\n",
    "rf3.fit(TrainFeaturesG3, TrainLabelsG3)\n",
    "rf4.fit(TrainFeaturesG4, TrainLabelsG4)\n",
    "\n",
    "# Run the model\n",
    "PredictG1 = rf1.predict(TestFeaturesG1)\n",
    "PredictG2 = rf2.predict(TestFeaturesG2)\n",
    "PredictG3 = rf3.predict(TestFeaturesG3)\n",
    "PredictG4 = rf4.predict(TestFeaturesG4)\n",
    "\n",
    "# Number of Test Label values\n",
    "TestNumberG1 = int(TestLabelsG1.shape[0])\n",
    "TestNumberG2 = int(TestLabelsG2.shape[0])\n",
    "TestNumberG3 = int(TestLabelsG3.shape[0])\n",
    "TestNumberG4 = int(TestLabelsG4.shape[0])\n",
    "\n",
    "PredictionsG1 = np.empty(shape=TestNumberG1, dtype=float)\n",
    "PredictionsG2 = np.empty(shape=TestNumberG2, dtype=float)\n",
    "PredictionsG3 = np.empty(shape=TestNumberG3, dtype=float)\n",
    "PredictionsG4 = np.empty(shape=TestNumberG4, dtype=float)\n",
    "\n",
    "# Relative Error\n",
    "RE1 = np.empty(shape=TestNumberG1, dtype=float)\n",
    "RE2 = np.empty(shape=TestNumberG2, dtype=float)\n",
    "RE3 = np.empty(shape=TestNumberG3, dtype=float)\n",
    "RE4 = np.empty(shape=TestNumberG4, dtype=float)\n",
    "\n",
    "# Convert to NumPy array to be used in further processing\n",
    "for i in range(0, TestNumberG1):\n",
    "    PredictionsG1[i] = float(PredictG1[i])\n",
    "    RE1[i] = float(abs((PredictionsG1[i]-TestLabelsG1[i])/TestLabelsG1[i]))\n",
    "for i in range(0, TestNumberG2):\n",
    "    PredictionsG2[i] = float(PredictG2[i])\n",
    "    RE2[i] = float(abs((PredictionsG2[i]-TestLabelsG2[i])/TestLabelsG2[i]))\n",
    "for i in range(0, TestNumberG3):\n",
    "    PredictionsG3[i] = float(PredictG3[i])\n",
    "    RE3[i] = float(abs((PredictionsG3[i]-TestLabelsG3[i])/TestLabelsG3[i]))\n",
    "for i in range(0, TestNumberG4):\n",
    "    PredictionsG4[i] = float(PredictG4[i])\n",
    "    RE4[i] = float(abs((PredictionsG4[i]-TestLabelsG4[i])/TestLabelsG4[i]))\n",
    "\n",
    "# Root Mean Square Error\n",
    "RMSE1 = sqrt(mean_squared_error(TestLabelsG1, PredictionsG1))\n",
    "RMSE2 = sqrt(mean_squared_error(TestLabelsG2, PredictionsG2))\n",
    "RMSE3 = sqrt(mean_squared_error(TestLabelsG3, PredictionsG3))\n",
    "RMSE4 = sqrt(mean_squared_error(TestLabelsG4, PredictionsG4))\n",
    "\n",
    "# Average Relative Error\n",
    "ARE1 = np.average(RE1)\n",
    "ARE2 = np.average(RE2)\n",
    "ARE3 = np.average(RE3)\n",
    "ARE4 = np.average(RE4)\n",
    "\n",
    "print('Task 1 Root Mean Square Error: ', round(RMSE1, 2))\n",
    "print('Task 1 Average Relative Error: ', round(ARE1, 2))\n",
    "\n",
    "print('Task 2 Root Mean Square Error: ', round(RMSE2, 2))\n",
    "print('Task 2 Average Relative Error: ', round(ARE2, 2))\n",
    "\n",
    "print('Task 3 Root Mean Square Error: ', round(RMSE3, 2))\n",
    "print('Task 3 Average Relative Error: ', round(ARE3, 2))\n",
    "\n",
    "print('Task 4 Root Mean Square Error: ', round(RMSE4, 2))\n",
    "print('Task 4 Average Relative Error: ', round(ARE4, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
