{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows:  20434\n",
      "Number of Columns:  11\n",
      "LA:  2270\n",
      "LB:  2628\n",
      "LC:  6496\n",
      "LD:  9034\n",
      "T:  20428\n",
      "Size Group 1: 567\n",
      "Size Group 2: 657\n",
      "Size Group 3: 1624\n",
      "Size Group 4: 2258\n",
      "Root Mean Square Error All:  123213.93\n",
      "Root Mean Square Error 1:  151806.45\n",
      "Root Mean Square Error 2:  158091.86\n",
      "Root Mean Square Error 3:  80882.44\n",
      "Root Mean Square Error 4:  128709.63\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "\n",
    "# Multi-Task Learning\n",
    "# With Cross Validation\n",
    "# Use 4 locations (ocean proximity)\n",
    "# Location 5 not used due to small number of data points\n",
    "\n",
    "# Update path according to file system\n",
    "PathToFile = str('')\n",
    "\n",
    "# Train to Test ratio\n",
    "TrainSize = float(0.8)\n",
    "TestSize = float(1.0 - TrainSize)\n",
    "\n",
    "# Group size\n",
    "LA = int(0.0)\n",
    "LB = int(0.0)\n",
    "LC = int(0.0)\n",
    "LD = int(0.0)\n",
    "T = int(0.0)\n",
    "\n",
    "# Removing rows with empty cells\n",
    "# Lines necessary only for the first run\n",
    "# MyDataP = pd.read_csv(PathToFile+'HousingMarket1.csv')\n",
    "# MyDataNewP = MyDataP.dropna(axis=0)\n",
    "# MyDataNewP.to_csv(PathToFile+'HousingMarket2.csv', sep=',', encoding='utf-8')\n",
    "\n",
    "# Acquire the datasets from the file system\n",
    "# Full dataset (20428 rows)\n",
    "# MyData = np.genfromtxt(PathToFile+'HousingMarket2.csv', delimiter=',', dtype='unicode')\n",
    "# Small dataset (80 rows)\n",
    "MyData = np.genfromtxt(PathToFile+'HousingMarket2.csv', delimiter=',', dtype='unicode')\n",
    "\n",
    "# Print dimensions of dataset\n",
    "print('Number of Rows: ', MyData.shape[0])\n",
    "print('Number of Columns: ', MyData.shape[1])\n",
    "\n",
    "# Extract dimensions of sub-datasets based on location (ocean proximity)\n",
    "for i in range(0, MyData.shape[0]):\n",
    "    if str(MyData[i, 10]) == 'NEAR BAY':\n",
    "        LA = LA + 1\n",
    "    if str(MyData[i][10]) == 'NEAR OCEAN':\n",
    "        LB = LB + 1\n",
    "    if str(MyData[i][10]) == 'INLAND':\n",
    "        LC = LC + 1\n",
    "    if str(MyData[i][10]) == '<1H OCEAN':\n",
    "        LD = LD + 1\n",
    "\n",
    "# Total number of rows\n",
    "T = int(LA + LB + LC + LD)\n",
    "\n",
    "print('LA: ', LA)\n",
    "print('LB: ', LB)\n",
    "print('LC: ', LC)\n",
    "print('LD: ', LD)\n",
    "print('T: ', T)\n",
    "\n",
    "MyDataNew = np.empty(shape=(T, 10), dtype=float)\n",
    "\n",
    "# Re-arrange dataset based on location (ocean proximity)\n",
    "# Add new column [0] to indicate location (0 - 3)\n",
    "# Ignoring the fifth location due to small number of data point\n",
    "k = int(0)\n",
    "for i in range(0, MyData.shape[0]):\n",
    "    if str(MyData[i][10]) == 'NEAR BAY':\n",
    "        MyDataNew[k][0] = int(0)\n",
    "        for j in range(1, 10):\n",
    "            try:\n",
    "                MyDataNew[k][j] = float(MyData[i][j])\n",
    "            except:\n",
    "                print('Error')\n",
    "        k = k + 1\n",
    "k = int(0)\n",
    "for i in range(0, MyData.shape[0]):\n",
    "    if str(MyData[i][10]) == 'NEAR OCEAN':\n",
    "        MyDataNew[LA+k][0] = int(1)\n",
    "        for j in range(1, 10):\n",
    "            try:\n",
    "                MyDataNew[LA+k][j] = float(MyData[i][j])\n",
    "            except:\n",
    "                print('Error')\n",
    "        k = k + 1\n",
    "k = int(0)\n",
    "for i in range(0, MyData.shape[0]):\n",
    "    if str(MyData[i][10]) == 'INLAND':\n",
    "        MyDataNew[LA+LB+k][0] = int(2)\n",
    "        for j in range(1, 10):\n",
    "            try:\n",
    "                MyDataNew[LA+LB+k][j] = float(MyData[i][j])\n",
    "            except:\n",
    "                print('Error')\n",
    "        k = k + 1\n",
    "k = int(0)\n",
    "for i in range(0, MyData.shape[0]):\n",
    "    if str(MyData[i][10]) == '<1H OCEAN':\n",
    "        MyDataNew[LA+LB+LC+k][0] = int(3)\n",
    "        for j in range(1, 10):\n",
    "            try:\n",
    "                MyDataNew[LA+LB+LC+k][j] = float(MyData[i][j])\n",
    "            except:\n",
    "                print('Error')\n",
    "        k = k + 1\n",
    "\n",
    "# Save pre-processed dataset\n",
    "# np.savetxt(PathToFile+'HousingMarket4.csv', MyDataNew, fmt='%f', delimiter=',')\n",
    "\n",
    "# Used for stratifying the dataset\n",
    "S = np.empty(shape=T, dtype=int)\n",
    "for i in range(0, LA):\n",
    "    S[i] = int(1)\n",
    "for i in range(LA, LA+LB):\n",
    "    S[i] = int(2)\n",
    "for i in range(LA+LB, LA+LB+LC):\n",
    "    S[i] = int(3)\n",
    "for i in range(LA+LB+LC, T):\n",
    "    S[i] = int(4)\n",
    "\n",
    "# Allocate space for Features and Labels\n",
    "FeaturesAll = np.empty(shape=(T, 9), dtype=float)\n",
    "LabelsAll = np.empty(shape=T, dtype=float)\n",
    "\n",
    "# Extract Features and Labels from dataset\n",
    "for i in range(0, T):\n",
    "    for j in range(0, 9):\n",
    "        FeaturesAll[i, j] = float(MyDataNew[i, j])\n",
    "    LabelsAll[i] = float(MyDataNew[i][9])\n",
    "\n",
    "# Split into 4 folds\n",
    "Splits = StratifiedKFold(n_splits=4, random_state=None, shuffle=False)\n",
    "\n",
    "i = int(0)\n",
    "# Cross Validation\n",
    "for TrainIndex, TestIndex in Splits.split(FeaturesAll, S):\n",
    "    i = i + 1\n",
    "    # print('Train: ', TrainIndex)\n",
    "    # print('Test: ', TestIndex)\n",
    "    TrainFeatures = FeaturesAll[TrainIndex]\n",
    "    TestFeatures = FeaturesAll[TestIndex]\n",
    "    TrainLabels = LabelsAll[TrainIndex]\n",
    "    TestLabels = LabelsAll[TestIndex]\n",
    "\n",
    "    # Initialise the Random Forest Regression object\n",
    "    rf = RandomForestRegressor(n_estimators=50, random_state=10)\n",
    "    # Train the model\n",
    "    rf.fit(TrainFeatures, TrainLabels)\n",
    "    # Run the model\n",
    "    if i == int(1):\n",
    "        PredictFold1 = rf.predict(TestFeatures)\n",
    "    if i == int(2):\n",
    "        PredictFold2 = rf.predict(TestFeatures)\n",
    "    if i == int(3):\n",
    "        PredictFold3 = rf.predict(TestFeatures)\n",
    "    if i == int(4):\n",
    "        PredictFold4 = rf.predict(TestFeatures)\n",
    "\n",
    "# Split the combined dataset with stratifying\n",
    "# TrainFeatures, TestFeatures, TrainLabels, TestLabels = train_test_split(FeaturesAll, LabelsAll, test_size=TestSize, stratify=S, random_state=5)\n",
    "\n",
    "# Number of Test Label values\n",
    "TestNumber = int(TestLabels.shape[0])\n",
    "\n",
    "SizeGroup1 = int(0)\n",
    "SizeGroup2 = int(0)\n",
    "SizeGroup3 = int(0)\n",
    "SizeGroup4 = int(0)\n",
    "\n",
    "# Calculate the sizes of each group\n",
    "# Comparing float data type\n",
    "for i in range(0, TestNumber):\n",
    "    if TestFeatures[i][0] < float(0.5):\n",
    "        SizeGroup1 = SizeGroup1 + 1\n",
    "    if float(0.5) < TestFeatures[i][0] < float(1.5):\n",
    "        SizeGroup2 = SizeGroup2 + 1\n",
    "    if float(1.5) < TestFeatures[i][0] < float(2.5):\n",
    "        SizeGroup3 = SizeGroup3 + 1\n",
    "    if float(2.5) < TestFeatures[i][0] < float(3.5):\n",
    "        SizeGroup4 = SizeGroup4 + 1\n",
    "\n",
    "print('Size Group 1:', SizeGroup1)\n",
    "print('Size Group 2:', SizeGroup2)\n",
    "print('Size Group 3:', SizeGroup3)\n",
    "print('Size Group 4:', SizeGroup4)\n",
    "\n",
    "PredictionsFold1 = np.empty(shape=TestNumber, dtype=float)\n",
    "PredictionsFold2 = np.empty(shape=TestNumber, dtype=float)\n",
    "PredictionsFold3 = np.empty(shape=TestNumber, dtype=float)\n",
    "PredictionsFold4 = np.empty(shape=TestNumber, dtype=float)\n",
    "\n",
    "# Predictions for each Group\n",
    "PredictionsGroup1 = np.empty(shape=SizeGroup1, dtype=float)\n",
    "PredictionsGroup2 = np.empty(shape=SizeGroup2, dtype=float)\n",
    "PredictionsGroup3 = np.empty(shape=SizeGroup3, dtype=float)\n",
    "PredictionsGroup4 = np.empty(shape=SizeGroup4, dtype=float)\n",
    "\n",
    "# Test Labels for each Group\n",
    "TestLabelsGroup1 = np.empty(shape=SizeGroup1, dtype=float)\n",
    "TestLabelsGroup2 = np.empty(shape=SizeGroup2, dtype=float)\n",
    "TestLabelsGroup3 = np.empty(shape=SizeGroup3, dtype=float)\n",
    "TestLabelsGroup4 = np.empty(shape=SizeGroup4, dtype=float)\n",
    "\n",
    "# Convert to NumPy array to be used in further processing\n",
    "for i in range(0, TestNumber):\n",
    "    PredictionsFold1[i] = float(PredictFold1[i])\n",
    "    PredictionsFold2[i] = float(PredictFold2[i])\n",
    "    PredictionsFold3[i] = float(PredictFold3[i])\n",
    "    PredictionsFold4[i] = float(PredictFold4[i])\n",
    "\n",
    "# From this point we have 4 tasks x 4 folds = 16 predicted targets\n",
    "\n",
    "# Using Fold 1\n",
    "# Change to PredictionsFold[2,3,4] to test other folds\n",
    "# Save Predictions and Test Labels into Groups\n",
    "k = int(0)\n",
    "for i in range(0, TestNumber):\n",
    "    if TestFeatures[i][0] < float(0.5):\n",
    "        PredictionsGroup1[k] = PredictionsFold1[i]\n",
    "        TestLabelsGroup1[k] = TestLabels[i]\n",
    "        k = k + 1\n",
    "k = int(0)\n",
    "for i in range(0, TestNumber):\n",
    "    if float(0.5) < TestFeatures[i][0] < float(1.5):\n",
    "        PredictionsGroup2[k] = PredictionsFold1[i]\n",
    "        TestLabelsGroup2[k] = TestLabels[i]\n",
    "        k = k + 1\n",
    "k = int(0)\n",
    "for i in range(0, TestNumber):\n",
    "    if float(1.5) < TestFeatures[i][0] < float(2.5):\n",
    "        PredictionsGroup3[k] = PredictionsFold1[i]\n",
    "        TestLabelsGroup3[k] = TestLabels[i]\n",
    "        k = k + 1\n",
    "k = int(0)\n",
    "for i in range(0, TestNumber):\n",
    "    if float(2.5) < TestFeatures[i][0] < float(3.5):\n",
    "        PredictionsGroup4[k] = PredictionsFold1[i]\n",
    "        TestLabelsGroup4[k] = TestLabels[i]\n",
    "        k = k + 1\n",
    "\n",
    "# Calculate Root Mean Square Error\n",
    "Task1RMSE = sqrt(mean_squared_error(TestLabelsGroup1, PredictionsGroup1))\n",
    "Task2RMSE = sqrt(mean_squared_error(TestLabelsGroup2, PredictionsGroup2))\n",
    "Task3RMSE = sqrt(mean_squared_error(TestLabelsGroup3, PredictionsGroup3))\n",
    "Task4RMSE = sqrt(mean_squared_error(TestLabelsGroup4, PredictionsGroup4))\n",
    "\n",
    "RMSE = sqrt(mean_squared_error(TestLabels, PredictionsFold1))\n",
    "\n",
    "print('Root Mean Square Error All: ', round(RMSE, 2))\n",
    "print('Root Mean Square Error 1: ', round(Task1RMSE, 2))\n",
    "print('Root Mean Square Error 2: ', round(Task2RMSE, 2))\n",
    "print('Root Mean Square Error 3: ', round(Task3RMSE, 2))\n",
    "print('Root Mean Square Error 4: ', round(Task4RMSE, 2))\n",
    "\n",
    "print('End')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
